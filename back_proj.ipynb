{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO1tGqWKpE7AxIgTUv4TOSN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amanzoni1/prove_varie/blob/main/back_proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Overview\n",
        "\n",
        "In the realm of computer vision, instance segmentation is a critical task with applications ranging from autonomous driving to augmented reality. Our project focuses on developing a sophisticated image processing pipeline that can segment people from images and seamlessly replace the background with various cities or tourist spots. This not only enhances visual aesthetics but also has potential applications in photography, virtual backgrounds for video conferencing, and creative media.\n",
        "\n",
        "We will leverage the COCO (Common Objects in Context) dataset, specifically focusing on the ‘person’ category. By utilizing a Mask R-CNN (Regional Convolutional Neural Network) model, we’ll perform precise segmentation of individuals in images. The project aims to deliver high-quality results suitable for practical use.\n",
        "\n",
        "## Key Objectives\n",
        "\n",
        "1. **Develop and Train a Neural Network Model:**\n",
        "   - Utilize a pre-trained Mask R-CNN model and fine-tune it for our specific task.\n",
        "\n",
        "2. **Implement Instance Segmentation:**\n",
        "   - Accurately segment people from images using advanced deep learning techniques.\n",
        "\n",
        "3. **Background Replacement:**\n",
        "   - Replace the original background with selected images of cities or tourist spots while maintaining the integrity of the foreground subject.\n",
        "\n",
        "4. **Utilize the COCO Dataset:**\n",
        "   - Work with a substantial subset of the COCO dataset containing images of people to train and validate our model effectively.\n",
        "\n",
        "5. **Create an Interactive Pipeline:**\n",
        "   - Develop a user-friendly interface within Colab for testing the model with custom images and backgrounds.\n",
        "\n",
        "# Project Details\n",
        "\n",
        "## Dataset\n",
        "\n",
        "**COCO (Common Objects in Context) Dataset:**\n",
        "\n",
        "- **Description:** A large-scale object detection, segmentation, and captioning dataset with over 200,000 images and 80 object categories.\n",
        "- **Usage in Project:** We’ll focus on images containing the ‘person’ category. A subset of 64,000 images has been downloaded and stored in Google Drive for this project.\n",
        "\n",
        "## Task\n",
        "\n",
        "Develop a pipeline that can:\n",
        "\n",
        "- **Segment individuals** in images with high accuracy.\n",
        "- **Replace the background** while preserving the foreground subject’s details.\n",
        "- **Maintain realistic blending** between the foreground and new background.\n",
        "\n",
        "## Approach\n",
        "\n",
        "1. **Exploratory Data Analysis (EDA):**\n",
        "   - Understand the dataset’s structure and contents.\n",
        "   - Visualize sample images and annotations to gain insights.\n",
        "\n",
        "2. **Data Preparation:**\n",
        "   - Implement a custom dataset class to load images and annotations.\n",
        "   - Apply data transformations and augmentations to enhance model robustness.\n",
        "\n",
        "3. **Model Setup:**\n",
        "   - Initialize a pre-trained Mask R-CNN model.\n",
        "   - Modify the model to suit our specific segmentation task.\n",
        "\n",
        "4. **Model Training:**\n",
        "   - Fine-tune the model using the prepared dataset.\n",
        "   - Monitor training progress and optimize performance.\n",
        "\n",
        "5. **Evaluation:**\n",
        "   - Assess the model’s performance using appropriate metrics.\n",
        "   - Visualize predictions to qualitatively evaluate segmentation quality.\n",
        "\n",
        "6. **Background Replacement Pipeline:**\n",
        "   - Develop functions to replace the background of segmented images.\n",
        "   - Ensure seamless integration between the foreground and new background.\n",
        "\n",
        "7. **Interactive Testing:**\n",
        "   - Create an interface in Colab for users to upload images and select backgrounds.\n",
        "   - Allow real-time testing of the segmentation and background replacement."
      ],
      "metadata": {
        "id": "jqu7C5JhYLyM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation"
      ],
      "metadata": {
        "id": "k1X0OglSZNbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "!pip install pycocotools\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKiug8KAYNYc",
        "outputId": "047b9c43-bd88-409e-c989-5fcf4bf29110"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (2.0.8)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sfbHFlJnZZqU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndZ73NyBZd0p",
        "outputId": "6c984634-98d3-4a10-83ea-be5fd0444c55"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = '/content/drive/MyDrive/COCO_person_dataset'\n",
        "annotations_dir = '/content/drive/MyDrive/COCO_annotations'\n",
        "\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "os.makedirs(annotations_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "gjCTxAIPZdyF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annotations_zip_path = '/content/annotations_trainval2017.zip'\n",
        "annotations_file = os.path.join(annotations_dir, 'instances_train2017.json')\n",
        "\n",
        "# Check if annotations already exist in Drive\n",
        "if not os.path.exists(annotations_file):\n",
        "    # Download annotations ZIP to Colab's local storage\n",
        "    !wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip -O {annotations_zip_path}\n",
        "\n",
        "    # Unzip the specific annotation file to Google Drive\n",
        "    !unzip -j {annotations_zip_path} annotations/instances_train2017.json -d {annotations_dir}\n",
        "\n",
        "    # Remove the ZIP file from Colab's local storage\n",
        "    os.remove(annotations_zip_path)\n",
        "else:\n",
        "    print(\"Annotations already exist in Google Drive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmtigIpZZdvW",
        "outputId": "6bed6025-c935-4c98-b7dc-c2bfc619d832"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-17 05:14:07--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 16.182.64.185, 3.5.28.143, 52.217.133.209, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|16.182.64.185|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252907541 (241M) [application/zip]\n",
            "Saving to: ‘/content/annotations_trainval2017.zip’\n",
            "\n",
            "/content/annotation 100%[===================>] 241.19M  92.2MB/s    in 2.6s    \n",
            "\n",
            "2024-09-17 05:14:10 (92.2 MB/s) - ‘/content/annotations_trainval2017.zip’ saved [252907541/252907541]\n",
            "\n",
            "Archive:  /content/annotations_trainval2017.zip\n",
            "  inflating: /content/drive/MyDrive/COCO_annotations/instances_train2017.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3gdDlKz-ZdsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to annotations file in Google Drive\n",
        "annotations_file = os.path.join(annotations_dir, 'instances_train2017.json')\n",
        "\n",
        "# Initialize COCO API\n",
        "coco = COCO(annotations_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEeWEQMVZdpv",
        "outputId": "b713c6ca-9945-489f-9265-8b3d6a1f93b3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=24.94s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B9ILKwm3Zdm2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all category IDs\n",
        "cat_ids = coco.getCatIds()\n",
        "\n",
        "# Get all image IDs\n",
        "img_ids = coco.getImgIds()\n",
        "\n",
        "print(f\"Number of categories: {len(cat_ids)}\")\n",
        "print(f\"Number of images: {len(img_ids)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5QORDHbZdkD",
        "outputId": "474032a4-9b1f-4b88-ae33-280b58bfd3b6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of categories: 80\n",
            "Number of images: 118287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get category ID for 'person'\n",
        "person_cat_id = coco.getCatIds(catNms=['person'])[0]\n",
        "\n",
        "# Get all image IDs containing the 'person' category\n",
        "img_ids = coco.getImgIds(catIds=[person_cat_id])\n",
        "print(f\"Total images with 'person' annotations: {len(img_ids)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR3C7aMfZdhT",
        "outputId": "d7927825-3462-4062-e0d5-2f4b0b811f78"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images with 'person' annotations: 64115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get list of image filenames in your dataset directory\n",
        "downloaded_filenames = set(os.listdir(dataset_dir))\n",
        "\n",
        "# Create a mapping from filename to image ID for images that exist\n",
        "filename_to_img_id = {}\n",
        "for img_id in img_ids:\n",
        "    img_info = coco.loadImgs(img_id)[0]\n",
        "    filename = img_info['file_name']\n",
        "    if filename in downloaded_filenames:\n",
        "        filename_to_img_id[filename] = img_id\n",
        "\n",
        "# Update img_ids to only include images you have downloaded\n",
        "img_ids = list(filename_to_img_id.values())\n",
        "print(f\"Number of images available for training: {len(img_ids)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPBI7ogcZdeq",
        "outputId": "f5b264aa-c3a0-4770-b722-0e8d24798df4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images available for training: 64115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0r2oO3yTZdb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vTW7v_2kZdZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ifOXVaO5ZdWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F4RW0QNBZdUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nlswBE8EZdRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2P1CJ550ZdPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dej47s8xZdMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qd9aBsNMZdKX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}